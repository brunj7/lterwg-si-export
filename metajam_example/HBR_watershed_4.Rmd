---
title: "HBR_watershed_4"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Step 1: Load packages
```{r}

library(metajam)  
library(udunits2)
# For wrangling the data
library(readr)
library(tidyr)
library(dplyr)
library(purrr)
library(stringr)
library(metajam)
library(tidyverse) # for convenience
library(here) # for file path management
library(stringdist) # for first pass of naming-matching
library(vctrs) # for joining tables
library(readxl) # for reading the template excel sheet



```

####Step 2: Find the link to the dataset
Go to the web address for the dataset and find the download button for the data. 

In our case the link is: https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-hbr.6.15&entityid=693eaf5a834ae7fecc5111a5ce0a420b

#### Step 3: Choose where you want the files to be saved
In our case, we'll just put it into the metajam_example folder.
```{r}

#eg desired_path_to_data <- "~/Desktop"
desired_path_to_data <- "/home/kpeach/R/SI_river_data/lterwg-si-export/metajam_example"


```

#### Step 4: Download the data by pasting the link you just copied

```{r}

# this will download the data into a folder and save the path to that folder
downloaded_data <- download_d1_data("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-hbr.6.15&entityid=693eaf5a834ae7fecc5111a5ce0a420b", path = desired_path_to_data)



```

#### Step 5: Now read in the data (with all the metadata)

```{r}

my_data <- read_d1_files(downloaded_data)

HBR_watershed_4_data <- my_data$data


```

###Step 6: data cleanup

```{r}

#There are 652 rows in this df
#Adding a column to identify the LTER site - Hubbar Brook HBR

LTER_name <- rep('HBR', 652)

HBR_watershed_4_data <- cbind(HBR_watershed_4_data, 'LTER' = LTER_name)

#There is no site name in the csv file so I pulled this site identifier from the data portal

Site_name <- rep('knb-lter-hbr.6.15', 652)

HBR_watershed_4_data <- cbind(HBR_watershed_4_data, 'Site/Stream Name' = Site_name)
# I can see that the column Year_Month includes the info from the column in the template 'Sampling Date' so I want to rename that column 

HBR_watershed_4_data <- HBR_watershed_4_data %>% 
  rename('Sampling Date' = 'Year_Month')

```

```{r}

#Removing the volwt_ preface from many of the column names. That preface was preventing me from identifying which columns were a match to the template 

names(HBR_watershed_4_data)[5:29] <- substring(names(HBR_watershed_4_data)[5:29],7,15)

HBR_watershed_4_data <- HBR_watershed_4_data %>% 
  rename('Si' = 'SiO2') 

HBR_watershed_4_data <- HBR_watershed_4_data %>% 
  rename('Spec Cond' = 'SpecCond')


```

Read in template
```{r}

template <- read_excel(here("metajam_example", "Stream_Data_Template.xlsx"), 
                               sheet = "Raw Data",
                               col_types = "text"
                               ) %>%
  mutate(`Sampling Date` = as.Date(`Sampling Date`))


```

Fuzzy match

```{r}

# Start by matching by closest name as a first pass. 
  # Note that we match the lower case names
  # Note that the weight i= 0.1 says that we will be more likely to match if watershed 1 = template + extra
(fuzzy_match <- tibble(template = names(template)) %>%
   mutate(watershed4 = names(HBR_watershed_4_data)[amatch(tolower(template), tolower(names(HBR_watershed_4_data)), maxDist = 1, weight = c(d=1,i=0.1,s=1,t=1))])
)


(lookup_table <- fuzzy_match %>%
  mutate(watershed4 = case_when(
    template %in% c("TOC", "TN", "TKN", "TDP", "PP", "PON", "DOP") ~ NA_character_,
    TRUE ~ watershed4)))

correct_colnames <- lookup_table$template



```

```{r}


lookup_table <- lookup_table %>%
  filter(!is.na(watershed4))

correct_colnames <- lookup_table$template

new_datatable4 <- HBR_watershed_4_data %>% 
        select(one_of(c(correct_colnames)))



```

```{r}

# Fix NAs. In this dataset "-888.888" is the missing value code. So we need to replace those with NAs
new_datatable4 <- na_if(new_datatable4, "-888.888")

new_datatable4 <- na_if(new_datatable4, "-888.88")



```

