---
title: "Metajam Example"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  list(
    echo = TRUE,
    collapse = TRUE)
  )
```

Suppose we have have a link to a dataset in a data repository and we want to import it into our R session. For this example, we'll use the Stream water chemistry data for Green Lake 1, 1985-2010: https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-nwt.107.10

The `metajam` package gives us a convenient way to get the data (and the metadata) into our `R` session.

#### Step 1: Install/load the metajam package
```{r, message= FALSE}
#devtools::install_github("NCEAS/metajam")
library(metajam)
library(tidyverse) # for convenience
library(here) # for file path management
```

#### Step 2: Find the link to the dataset
Go to the web address for the dataset and find the download button for the data. In general, right-clicking this and clicking "Copy Link" should do the trick. 

```{r, out.width= "50%", echo= FALSE}
include_graphics(path = here("metajam_example", "metajam_dataset_link.png"))
```

In our case this link is: https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-nwt.107.10&entityid=aef605d3ab0fba82ec95f665ff4b066b

#### Step 3: Choose where you want the files to be saved
In our case, we'll just put it into the metajam_example folder.
```{r}
#eg desired_path_to_data <- "~/Desktop"
desired_path_to_data <- here("metajam_example")
```


#### Step 4: Download the data by pasting the link you just copied
```{r}
# this will download the data into a folder and save the path to that folder
downloaded_data <- download_d1_data("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-nwt.107.10&entityid=aef605d3ab0fba82ec95f665ff4b066b", path = desired_path_to_data)
```

#### Step 5: Now read in the data (with all the metadata)
```{r, message = FALSE}
my_data <- read_d1_files(downloaded_data)
```


Let's take a look at what we just read into `R`:
```{r}
summary(my_data)
```

It's a list of 4 dataframes! With this, everything we need is inside our `R` environment. 

#### Taking a deeper look at each of these dataframes

The dataset of interest:
```{r}
my_data$data
```

It's a good idea at this point to check that the column types are all correct. For instance, we notice that the `ANC` column is a character vector, rather than numeric. If we look a little deeper at this column, we find that this is because there are a few entries that say "NP" instead of a number.
```{r}
my_data$data %>%
  filter(ANC == "NP")
```


__Question__: What does NP mean in the `ANC` column?

To answer this, we can look at the attribute metadata that came with this dataset, which looks like this:
```{r}
my_data$attribute_metadata
```

To answer our question, we can just pull out the part of the dataframe we're interested in:
```{r}
my_data$attribute_metadata %>%
  filter(attributeName == "ANC") %>%
  select(attributeName, attributeDefinition)
```
So this tells us that NP means "not performed"! We can now deal with this column however is most appropriate for our analysis (for example, we can convert the NP into missing values and make the column numeric)

__Question__: What are the exact coordinate boundaries of the dataset?  
For this, we can look at the summary metadata:
```{r}
my_data$summary_metadata
```

To answer our question, we just subset the data we're interested in:
```{r}
# pull out all of the rows where name contains "BoundingCoordinate"
my_data$summary_metadata %>%
  filter(str_detect(name, "BoundingCoordinate"))
```

These are just a few examples of the kinds of questions we can answer with the metadata! Hopefully this gives you enough to speed up the data importing stage and get started with your analysis.

-------

_Note_: There is also a `factor_metadata` dataframe inside `my_data`. This dataset doesn't contain any factor variables, so `factor_metadata` is an empty dataframe that can be ignored.







